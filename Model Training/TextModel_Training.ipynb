{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextModel-Training.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOu17QKlKb7otEPndeUvfDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agiagoulas/page-stream-segmentation/blob/master/Model%20Training/TextModel_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26g5ik5t0Xv_"
      },
      "source": [
        "# Setup & Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJgSRbWb0bIY"
      },
      "source": [
        "Connect to Google Drive when working in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aluLZfzisSAe",
        "outputId": "539df631-1425-4b91-a815-8224524c3a77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqGReoW90gv1"
      },
      "source": [
        "Set working directory "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrN0yqgkmTkU"
      },
      "source": [
        "working_dir = \"/sample_directory/\" # TODO: Set correct working directory"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNFjAEZy0jid"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqGmgL1kMKo"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "!pip install fastText/.\n",
        "import csv, re, math\n",
        "import sklearn.metrics as sklm\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from importlib import reload\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.utils import *\n",
        "from keras.callbacks import ModelCheckpoint, Callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko9L3vEB0nUn"
      },
      "source": [
        "Private Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iy_WO-4lpZa"
      },
      "source": [
        "model_request = requests.get(\"https://raw.githubusercontent.com/agiagoulas/page-stream-segmentation/master/app/pss/model.py\")\n",
        "with open(\"model.py\", \"w\") as f:\n",
        "    f.write(model_request.text)\n",
        "import model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0YN96Uj0k3t"
      },
      "source": [
        "Get fasttext word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fleFdm8JlupX"
      },
      "source": [
        "if 'ft' not in locals():\n",
        "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
        "    !unzip wiki.en.zip\n",
        "    ft = fasttext.load_model(\"wiki.en.bin\")\n",
        "model.ft = ft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rerafuX0qQY"
      },
      "source": [
        "Load Tobacco800 Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Yo3qikmUUM"
      },
      "source": [
        "data_train = model.read_csv_data(working_dir + \"tobacco800.train\")\n",
        "data_test = model.read_csv_data(working_dir + \"tobacco800.test\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlliiJzc0tgU"
      },
      "source": [
        "# Single Page Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LzoCrcD0yUi"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h9zx6zlxH_W"
      },
      "source": [
        "n_repeats = 1\n",
        "n_epochs = 1\n",
        "single_page_metric_history = []\n",
        "optimize_for = 'kappa'\n",
        "\n",
        "for i in range(n_repeats):\n",
        "    print(\"Repeat \" + str(i+1) + \" of \" + str(n_repeats))\n",
        "    print(\"--------------------\")\n",
        "    model_singlepage = model.compile_model_singlepage()\n",
        "    model_file = working_dir + \"tobacco800_text_single-page_%02d.hdf5\" % (i)\n",
        "    print(model_file)\n",
        "    checkpoint = model.ValidationCheckpoint(model_file, data_test, prev_page_generator=False, metric=optimize_for)\n",
        "    model_singlepage.fit(model.TextFeatureGenerator(data_train, prevpage=False, train=True),\n",
        "                    callbacks = [checkpoint],\n",
        "                    epochs = n_epochs)\n",
        "    single_page_metric_history.append(checkpoint.max_metrics)\n",
        "\n",
        "print(single_page_metric_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saM-O3f20zsB"
      },
      "source": [
        "Show metric results from different models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WopOlVayudI"
      },
      "source": [
        "for i, r in enumerate(single_page_metric_history):\n",
        "    model_file = working_dir + \"tobacco800_text_single-page_%02d.hdf5\" % (i)\n",
        "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_micro']) + ' ' + str(r['f1_macro']) + ' ' +  model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU5ZZqTy06o9"
      },
      "source": [
        "Load model and generate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roizjVt8z8vO"
      },
      "source": [
        "model_singlepage = model.compile_model_singlepage()\n",
        "model_singlepage.load_weights(working_dir + \"tobacco800_text_single-page_00.hdf5\")\n",
        "y_predict = np.round(model_singlepage.predict(model.TextFeatureGenerator(data_test, prevpage=False, train=False)))\n",
        "y_true = [model.LABEL2IDX[x[3]] for x in data_test]\n",
        "\n",
        "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
        "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))\n",
        "print(\"F1 Micro \" + str(sklm.f1_score(y_true, y_predict, average='micro')))\n",
        "print(\"F1 Macro \" + str(sklm.f1_score(y_true, y_predict, average='macro')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClFLnJp20-uk"
      },
      "source": [
        "# Current & Prev Page Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvcDS9bC1CKc"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ril34dvnmgV0"
      },
      "source": [
        "n_repeats = 1 # 10\n",
        "n_epochs = 1 # 20\n",
        "prev_page_metric_history = []\n",
        "optimize_for = 'kappa'\n",
        "\n",
        "for i in range(n_repeats):\n",
        "    print(\"Repeat \" + str(i+1) + \" of \" + str(n_repeats))\n",
        "    print(\"--------------------\")\n",
        "    model_prevpage = model.compile_model_prevpage()\n",
        "    model_file = working_dir + \"tobacco800_text_prev-page_%02d.hdf5\" % (i)\n",
        "    print(model_file)\n",
        "    checkpoint = model.ValidationCheckpoint(model_file, data_test, prev_page_generator=True, metric=optimize_for)\n",
        "    model_prevpage.fit(model.TextFeatureGenerator(data_train, prevpage=True, train=True),\n",
        "                    callbacks = [checkpoint],\n",
        "                    epochs = n_epochs)\n",
        "    prev_page_metric_history.append(checkpoint.max_metrics)\n",
        "\n",
        "print(prev_page_metric_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEuSzhwX1D4V"
      },
      "source": [
        "Show metric results from different models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCZCAKuvynoH"
      },
      "source": [
        "for i, r in enumerate(prev_page_metric_history):\n",
        "    model_file = working_dir + \"tobacco800_text_prev-page_%02d.hdf5\" % (i)\n",
        "    print(str(i) + ' ' + str(r['kappa']) + ' ' + str(r['accuracy']) + ' ' + str(r['f1_micro']) + ' ' + str(r['f1_macro']) + ' ' +  model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v285dCXy1HbU"
      },
      "source": [
        "Load model and generate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU9HGArnzLDt"
      },
      "source": [
        "model_prevpage = model.compile_model_prevpage()\n",
        "model_prevpage.load_weights(working_dir + \"tobacco800_text_prev-page_00.hdf5\")\n",
        "y_predict = np.round(model_prevpage.predict(model.TextFeatureGenerator(data_test, prevpage=True, train=False)))\n",
        "y_true = [model.LABEL2IDX[x[3]] for x in data_test]\n",
        "\n",
        "print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predict)))\n",
        "print(\"Kappa: \" + str(sklm.cohen_kappa_score(y_true, y_predict)))\n",
        "print(\"F1 Micro \" + str(sklm.f1_score(y_true, y_predict, average='micro')))\n",
        "print(\"F1 Macro \" + str(sklm.f1_score(y_true, y_predict, average='macro')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}